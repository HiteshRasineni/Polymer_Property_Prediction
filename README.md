# NeurIPS 2025 â€“ Polymer Property Prediction ğŸš€

This repository contains our solution for the **NeurIPS 2025 Open Polymer Prediction Challenge**.  
We use a **multi-modal gated fusion model** that combines:

- **ChemBERTa-77M-MTR** (Transformer-based SMILES embeddings)  
- **RNN with Attention** (character-level SMILES encoder)  
- **RDKit Descriptors** (molecular property features)  

with **Optuna-tuned hyperparameters** for robust performance on polymer property prediction.

---

## ğŸ“‚ Project Structure

```text
.
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
â”œâ”€â”€ train_supplement/
â”‚   â”œâ”€â”€ dataset1.csv   # Tc supplementary
â”‚   â”œâ”€â”€ dataset3.csv   # Tg supplementary
â”‚   â”œâ”€â”€ dataset4.csv   # FFV supplementary
â”œâ”€â”€ sample_submission.csv
â”œâ”€â”€ main.py            # Training & inference pipeline
â””â”€â”€ submission.csv     # Final Kaggle output
```
---

## âš™ï¸ Requirements

The code is designed for **Kaggle** with RDKit wheels and ChemBERTa checkpoint preloaded.  
Installed at runtime:

- `rdkit-pypi==2022.9.5`  
- `torch`, `transformers`, `numpy`, `pandas`, `scikit-learn`, `tqdm`, `optuna`  
- `xgboost`, `lightgbm`, `catboost` (optional ensembling)

---

## ğŸ§ª Data

We train on:

- **Main training set** â†’ `train.csv`  
- **Supplementary sets**:  
  - `dataset3.csv` â†’ Tg values  
  - `dataset4.csv` â†’ FFV values  
  - `dataset1.csv` â†’ Tc values  

All supplementary datasets are merged into a single `train_full`.  
Missing targets are marked as `NaN` and handled with **masked loss**.  

**Targets:** `Tg`, `FFV`, `Tc`, `Density`, `Rg`.

---

## ğŸ—ï¸ Model Architecture

**FusionModel** = `ChemBERTa + RNN + RDKit` with **gated fusion**:

1. **ChemBERTa-MTR** â†’ SMILES transformer embeddings.  
2. **BiGRU + Attention** â†’ character-level SMILES encoder.  
3. **RDKit MLP** â†’ MolWt, LogP, TPSA, HDonors, HAcceptors.  
4. **Gate mechanism** blends RNN+ChemBERTa with RDKit.  
5. **Final MLP head** â†’ predict 5 polymer properties.  

---

## ğŸ”¥ Training

- Optimizer: **Adam**  
- Learning rate: **0.00095**  
- Loss: **Masked MSE** (ignores missing targets)  
- Epochs: **40**  
- Batch size: **16**  
- Best checkpoint saved as `best_model.pt`.

---

## ğŸ“Š Inference

1. Load best checkpoint.  
2. Predict on `test.csv`.  
3. Inverse transform predictions back to original units.  
4. Save `submission.csv`.  

---

## â–¶ï¸ Usage

```bash
python main.py
